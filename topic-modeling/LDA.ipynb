{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd04ef8975e22676df32c930aae12a41200d93f0ab6e5e4fbe73ecc9ad618aa940e",
   "display_name": "Python 3.8.5 64-bit ('venv')"
  },
  "metadata": {
   "interpreter": {
    "hash": "4ef8975e22676df32c930aae12a41200d93f0ab6e5e4fbe73ecc9ad618aa940e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "access = os.environ.get('AWS_ACCESS')\n",
    "secret = os.environ.get('AWS_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import ArrayType, StringType, TimestampType, DateType, StructType, DoubleType, IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StopWordsRemover\n",
    "from pyspark.ml import Pipeline, PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .set(\"fs.s3a.awsAccessKeyId\", access) \\\n",
    "    .set(\"fs.s3a.awsSecretAccessKey\", secret) \\\n",
    "    .set(\"fs.s3a.endpoint\", \"s3.us-east-1.amazonaws.com\") \\\n",
    "    .set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .set(\"fs.s3a.impl\",\"org.apache.hadoop.fs.s3native.NativeS3FileSystem\") \\\n",
    "    .set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "\n",
    "spark = SparkSession.builder.master('local').appName('cool').config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# filename = 's3a://patellism/processed_data/2020-08-cleaned.parquet.snappy/part-00004-d2d9c5cf-46de-47d9-86df-28fefd1709e5-c000.snappy.parquet'\n",
    "filename = '2020-08-cleaned-small.parquet.snappy'\n",
    "df = spark.read.parquet(filename).drop('geo', 'coordinates', 'place', 'retweet_count', 'favorite_count')\n",
    "df = df.withColumn('datetime', df['created_at'].cast(TimestampType())).drop('created_at')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['say',\n",
       " 'trump',\n",
       " 'make',\n",
       " 'people',\n",
       " 'work',\n",
       " 'enough',\n",
       " 'im',\n",
       " 'get',\n",
       " 'biden',\n",
       " 'american',\n",
       " 'one',\n",
       " 'good',\n",
       " 'need',\n",
       " 'time',\n",
       " 'amp',\n",
       " 'president',\n",
       " 'state',\n",
       " 'we',\n",
       " 'racist',\n",
       " 'use',\n",
       " 'cant',\n",
       " 'democrat',\n",
       " 'even',\n",
       " 'think',\n",
       " 'go',\n",
       " 'u',\n",
       " 'see',\n",
       " 'right',\n",
       " 'vote',\n",
       " 'many',\n",
       " 'america',\n",
       " 'thing',\n",
       " 'week',\n",
       " 'read']"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# This is a disguisting way to do this. If the data is too large could outofmemory\n",
    "\n",
    "# Make sure the countvectorize params are the same as the below pipeline\n",
    "cv = CountVectorizer(inputCol='clean_text', outputCol='output', vocabSize=5000, minDF=1)\n",
    "model = cv.fit(df)\n",
    "cv_df = model.transform(df)\n",
    "\n",
    "vocab = model.vocabulary\n",
    "combined = df.select(explode('clean_text').alias('col')).select(collect_list('col').alias('clean_text'))\n",
    "counts = model.transform(combined).select('output').collect()\n",
    "\n",
    "count_list = list(zip(model.vocabulary, counts[0]['output'].values))\n",
    "num_removed = int(0.05*len(count_list))\n",
    "\n",
    "to_remove = []\n",
    "for i in range(num_removed):\n",
    "    to_remove.append(count_list[i][0])\n",
    "\n",
    "to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_freq_words = StopWordsRemover(inputCol='clean_text', outputCol='clean_rm_frequent', stopWords=to_remove)\n",
    "cv_tf = CountVectorizer(inputCol='clean_rm_frequent', outputCol='features', vocabSize=5000, minDF=1)\n",
    "lda_tf = LDA(k=3, maxIter=20)\n",
    "\n",
    "tf_pipeline = Pipeline(stages=[rm_freq_words, cv_tf, lda_tf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three groupings\n",
    "#   Ungrouped\n",
    "#   Time\n",
    "#   Hashtags\n",
    "#       Need to determine similarity metrics and method for tweets with no hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------------------------------+\n|word                                   |\n+---------------------------------------+\n|[puppet, you, everyone, could, gotta]  |\n|[kid, believe, country, teacher, give] |\n|[faith, respect, lose, truth, election]|\n+---------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "model_tf = tf_pipeline.fit(df)\n",
    "\n",
    "topics_tf = model_tf.stages[-1].describeTopics(maxTermsPerTopic=5)\n",
    "vocabArray_tf = model_tf.stages[1].vocabulary\n",
    "\n",
    "def covertToWord(indices):\n",
    "    result = []\n",
    "    for i in indices:\n",
    "        result.append(vocabArray_tf[i])\n",
    "    return result\n",
    "\n",
    "udf_convertToWord = udf(covertToWord, ArrayType(StringType()))\n",
    "topics_tf = topics_tf.withColumn('word', udf_convertToWord('termIndices'))\n",
    "topics_tf.select('word').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+--------------------+--------+--------------------+-------------------+--------------------+--------------------+--------------------+\n|                 id|           full_text|hashtags|          clean_text|           datetime|   clean_rm_frequent|            features|   topicDistribution|\n+-------------------+--------------------+--------+--------------------+-------------------+--------------------+--------------------+--------------------+\n|1291569732789981185|@JRILLaw @Lrihend...|      []|[litigator, abili...|2020-08-06 22:59:55|[litigator, abili...|(655,[39,48,154,1...|[0.02138893474753...|\n|1291569732924010496|@Jehi001 @Bibathe...|      []|[get, lose, vile,...|2020-08-06 22:59:55|[lose, vile, unca...|(655,[12,139,254,...|[0.04251318820887...|\n|1291569734735917057|@granada761 @Real...|      []|[house, discrimin...|2020-08-06 22:59:55|[house, discrimin...|(655,[2,4,19,31,3...|[0.01425062821245...|\n|1291569735994183685|@metawoke @Halani...|      []|[know, one, real,...|2020-08-06 22:59:55|[know, real, coro...|(655,[6,7,11,15,4...|[0.02621039282765...|\n|1291569736455782401|@RepMattGaetz @re...|      []|[want, enjoin, so...|2020-08-06 22:59:56|[want, enjoin, so...|(655,[14,32,46,81...|[0.92880248422368...|\n+-------------------+--------------------+--------+--------------------+-------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "transformed_tf = model_tf.transform(df)\n",
    "transformed_tf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -6719.647641050866\nThe upper bound on perplexity: 7.558658763836744\n"
     ]
    }
   ],
   "source": [
    "ll = model_tf.stages[-1].logLikelihood(transformed_tf)\n",
    "lp = model_tf.stages[-1].logPerplexity(transformed_tf)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+--------------------+--------------------+\n| day_mo_yr|am_or_pm|          clean_text|             id_list|\n+----------+--------+--------------------+--------------------+\n|2020-08-06|       1|[litigator, abili...|[1291569732789981...|\n+----------+--------+--------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Group by time\n",
    "time_df = df.drop('full_text', 'hashtags')\n",
    "\n",
    "time_df = time_df.withColumn('day_mo_yr', date_format('datetime', 'yyyy-MM-dd'))\n",
    "time_df = time_df.withColumn('hour', hour('datetime'))\n",
    "\n",
    "def amOrPm(hour):\n",
    "    res = hour - 12\n",
    "    if res < 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "udf_amOrPm = udf(amOrPm, IntegerType())\n",
    "time_df = time_df.withColumn('am_or_pm', udf_amOrPm('hour'))\n",
    "\n",
    "time_df = \\\n",
    "    time_df.withColumn('clean_text', explode('clean_text')) \\\n",
    "    .groupBy('day_mo_yr', 'am_or_pm') \\\n",
    "    .agg(collect_list('clean_text'), collect_list('id')) \\\n",
    "    .withColumnRenamed('collect_list(clean_text)', 'clean_text') \\\n",
    "    .withColumnRenamed('collect_list(id)', 'id_list')\n",
    "\n",
    "time_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_idf = CountVectorizer(inputCol='clean_text', outputCol='raw_features', vocabSize=5000, minDF=3)\n",
    "# idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "# lda_tfidf = LDA(k=3, maxIter=20)\n",
    "\n",
    "# tfidf_pipeline = Pipeline(stages=[cv_idf, idf, lda_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_idf = tfidf_pipeline.fit(df)\n",
    "\n",
    "# topics_idf = model_idf.stages[-1].describeTopics(maxTermsPerTopic=5)\n",
    "# vocabArray_idf = model_idf.stages[0].vocabulary\n",
    "\n",
    "# def covertToWord(indices):\n",
    "#     result = []\n",
    "#     for i in indices:\n",
    "#         result.append(vocabArray_idf[i])\n",
    "#     return result\n",
    "\n",
    "# udf_convertToWord = udf(covertToWord, ArrayType(StringType()))\n",
    "# topics_idf = topics_idf.withColumn('word', udf_convertToWord('termIndices'))\n",
    "# topics_idf.select('word').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_idf = model_idf.transform(df)\n",
    "# transformed_idf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll = model_idf.stages[-1].logLikelihood(transformed_idf)\n",
    "# lp = model_idf.stages[-1].logPerplexity(transformed_idf)\n",
    "# print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "# print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  }
 ]
}