{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "access = os.environ.get('AWS_ACCESS')\n",
    "secret = os.environ.get('AWS_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, Normalizer,\n",
    "                                LemmatizerModel, StopWordsCleaner)\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8711aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .set(\"fs.s3a.awsAccessKeyId\", access) \\\n",
    "    .set(\"fs.s3a.awsSecretAccessKey\", secret) \\\n",
    "    .set(\"fs.s3a.endpoint\", \"s3.us-east-1.amazonaws.com\") \\\n",
    "    .set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .set(\"fs.s3a.impl\",\"org.apache.hadoop.fs.s3native.NativeS3FileSystem\") \\\n",
    "    .set(\"com.amazonaws.services.s3.enableV4\", \"true\")\n",
    "\n",
    "spark = SparkSession.builder.master('local').appName('cool').config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "33085160",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s3_file = ''\n",
    "df = spark.read.parquet(s3_file).drop('geo', 'coordinates', 'place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "65e8dd22",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- id: long (nullable = true)\n |-- full_text: string (nullable = true)\n |-- retweet_count: double (nullable = true)\n |-- favorite_count: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1fed2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetPreprocessor(text):\n",
    "    p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.SMILEY, p.OPT.NUMBER)\n",
    "    text = p.clean(text)\n",
    "    return text\n",
    "tweetPreprocessor_udf = udf(tweetPreprocessor, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+--------------------+-------------+--------------+--------------------+\n|                 id|           full_text|retweet_count|favorite_count|               clean|\n+-------------------+--------------------+-------------+--------------+--------------------+\n|1300070747059167233|@kmiranda1973 @Mi...|          0.0|           2.0|@kmiranda1973 @Mi...|\n|1300070747453427713|@realDonaldTrump ...|          0.0|           0.0|@realDonaldTrump ...|\n|1300070747566755845|@realDonaldTrump ...|          0.0|           1.0|@realDonaldTrump ...|\n|1300070748116131840|@EricTrump @realD...|          0.0|           1.0|@EricTrump @realD...|\n|1300070748359454721|Impeached @realdo...|          0.0|           1.0|Impeached @realdo...|\n+-------------------+--------------------+-------------+--------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('clean', tweetPreprocessor_udf('full_text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('clean') \\\n",
    "    .setOutputCol('document') \\\n",
    "    .setCleanupMode('shrink_full')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols(['token']) \\\n",
    "    .setOutputCol('normalized') \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "    .setInputCols(['normalized']) \\\n",
    "    .setOutputCol('lemma')\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols(['lemma']) \\\n",
    "    .setOutputCol('clean_text') \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setStopWords(stopwords_list)\n",
    "\n",
    "finisher = Finisher() \\\n",
    "     .setInputCols(['clean_text']) \\\n",
    "     .setCleanAnnotations(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline() \\\n",
    "     .setStages([\n",
    "           documentAssembler,\n",
    "           tokenizer,\n",
    "           normalizer,\n",
    "           lemmatizer,\n",
    "           stopwords_cleaner,\n",
    "           finisher\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+--------------------+-------------+--------------+--------------------+\n|                 id|           full_text|retweet_count|favorite_count|          clean_text|\n+-------------------+--------------------+-------------+--------------+--------------------+\n|1300070747059167233|@kmiranda1973 @Mi...|          0.0|           2.0|[kmiranda, militi...|\n|1300070747453427713|@realDonaldTrump ...|          0.0|           0.0|[realdonaldtrump,...|\n|1300070747566755845|@realDonaldTrump ...|          0.0|           1.0|[realdonaldtrump,...|\n|1300070748116131840|@EricTrump @realD...|          0.0|           1.0|[erictrump, reald...|\n|1300070748359454721|Impeached @realdo...|          0.0|           1.0|[impeach, realdon...|\n|1300070748367785985|@PollWatch2020 @r...|          0.0|           0.0|[pollwatch, reald...|\n|1300070748631916548|@RichLowry @realD...|          0.0|           0.0|[richlowry, reald...|\n|1300070748942344192|@realDonaldTrump ...|          0.0|           1.0|[realdonaldtrump,...|\n|1300070749336727556|@eugenegu @realDo...|          0.0|           0.0|[eugenegu, realdo...|\n|1300070749374476288|@realDonaldTrump ...|          0.0|           0.0|[realdonaldtrump,...|\n|1300070750057951232|@realDonaldTrump ...|          0.0|           0.0|[realdonaldtrump,...|\n|1300070750057975808|@realDonaldTrump ...|          0.0|           0.0|   [realdonaldtrump]|\n|1300070750951550976|@EricTrump @realD...|          0.0|           0.0|[erictrump, reald...|\n|1300070751903645696|@ElvisKirby4 @jas...|          0.0|           0.0|[elviskirby, jass...|\n|1300070752104992768|@realDonaldTrump ...|          0.0|           0.0|[realdonaldtrump,...|\n|1300070752763346949|People who donâ€™t ...|          0.0|           0.0|[people, dont, ev...|\n|1300070752788545537|@RacismWoke @manp...|          0.0|           0.0|[racismwoke, manp...|\n|1300070753501687810|@themisst1 @Huber...|          0.0|           1.0|[themisst, hubert...|\n|1300070754327891968|@VicBergerIV @rea...|          0.0|           1.0|[vicbergeriv, rea...|\n|1300070754378305536|@KamVTV @davidcic...|          0.0|           3.0|[kamvtv, davidcic...|\n+-------------------+--------------------+-------------+--------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = pipeline.fit(df).transform(df)\n",
    "df = df.drop('clean').withColumnRenamed('finished_clean_text', 'clean_text')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_write = ''\n",
    "df.write.parquet(s3_write, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd04ef8975e22676df32c930aae12a41200d93f0ab6e5e4fbe73ecc9ad618aa940e",
   "display_name": "Python 3.8.5 64-bit ('venv')"
  },
  "metadata": {
   "interpreter": {
    "hash": "4ef8975e22676df32c930aae12a41200d93f0ab6e5e4fbe73ecc9ad618aa940e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}